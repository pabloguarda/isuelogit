{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = RuntimeWarning)\n",
    "\n",
    "# External modules\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main dir: /Users/pablo/OneDrive/data-science/github/isuelogit\n"
     ]
    }
   ],
   "source": [
    "# Path management\n",
    "main_dir = str(Path(os.path.abspath('')).parents[0])\n",
    "os.chdir(main_dir)\n",
    "print('main dir:',main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal modules\n",
    "from src import isuelogit as isl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "_SEED = 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read network data from Fresno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected date is 2019-10-01, Tuesday at 16:00\n"
     ]
    }
   ],
   "source": [
    "network_name = 'Fresno'\n",
    "\n",
    "# To write estimation report and set seed for all algorithms involving some randomness  \n",
    "estimation_reporter = isl.writer.Reporter(\n",
    "    folderpath = isl.config.dirs['output_folder'] + 'estimations/' + network_name, seed = _SEED)\n",
    "\n",
    "# Reader of geospatial and spatio-temporal data\n",
    "data_reader = isl.etl.DataReader(network_key=network_name)\n",
    "\n",
    "# First Tuesday of October, 2019\n",
    "data_reader.select_period(date='2019-10-01', hour=16)\n",
    "\n",
    "# Read nodes data\n",
    "nodes_df = pd.read_csv(isl.dirs['input_folder'] + '/network-data/nodes/'  + 'fresno-nodes-data.csv')\n",
    "\n",
    "# Read spatiotemporal link data\n",
    "links_df = pd.read_csv(\n",
    "    isl.dirs['input_folder'] + 'network-data/links/' + str(data_reader.options['selected_date'])+ '-fresno-link-data.csv',\n",
    "    converters={\"link_key\": ast.literal_eval,\"pems_id\": ast.literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Fresno network\n",
      "\n",
      "Nodes: 1789, Links: 2413\n"
     ]
    }
   ],
   "source": [
    "network_generator = isl.factory.NetworkGenerator()\n",
    "\n",
    "A = network_generator.generate_adjacency_matrix(links_keys=list(links_df['link_key'].values))\n",
    "\n",
    "fresno_network = \\\n",
    "    network_generator.build_fresno_network(A=A, links_df=links_df, nodes_df=nodes_df, network_name= network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Q (1789, 1789) read in 0.0[s] with sparse format\n",
      "66266.3 trips were loaded among 6970 o-d pairs\n"
     ]
    }
   ],
   "source": [
    "network_generator.read_OD(network=fresno_network, sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading paths: |####----------------| 21.6% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13905 paths were read in 16.6[s]              \n",
      "\n",
      "13905 paths were loaded in the network\n",
      "\n",
      "Updating incidence matrices\n",
      "\n",
      "Matrix D (2413, 13905) generated in 35.4[s] \n",
      "\n",
      "Matrix M (6970, 13905) generated in 12.7[s] \n",
      "\n",
      "Matrix C (13905, 13905) generated in 6.7[s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paths_generator = isl.factory.PathsGenerator()\n",
    "\n",
    "# # Generate and Load paths in network\n",
    "# paths_generator.load_k_shortest_paths(network = fresno_network, k=3)\n",
    "\n",
    "# Read and load paths in network\n",
    "paths_generator.read_paths(network=fresno_network, update_incidence_matrices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link performance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_parameters_df = pd.DataFrame({'link_key': links_df['link_key'],\n",
    "                                  'alpha': links_df['alpha'],\n",
    "                                  'beta': links_df['beta'],\n",
    "                                  'tf': links_df['tf_inrix'],\n",
    "                                  #'tf': links_df['tf'],\n",
    "                                  'k': pd.to_numeric(links_df['k'], errors='coerce', downcast='float')\n",
    "                                  })\n",
    "\n",
    "# Normalize free flow travel time between 0 and 1\n",
    "bpr_parameters_df['tf'] = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(np.array(bpr_parameters_df['tf']).reshape(-1, 1)))\n",
    "\n",
    "fresno_network.set_bpr_functions(bprdata=bpr_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features values of links with a type different than LWRLK were set to 0\n",
      "New features: ['low_inc', 'high_inc', 'no_incidents', 'no_bus_stops', 'no_intersections', 'tt_sd_adj', 'tt_reliability']\n"
     ]
    }
   ],
   "source": [
    "fresno_network.load_features_data(links_df, link_key = 'link_key')\n",
    "\n",
    "isl.etl.feature_engineering_fresno(links=fresno_network.links, network=fresno_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['median_inc', 'intersections', 'incidents', 'bus_stops', 'median_age',\n",
    "                 'tt_avg', 'tt_sd','tt_var', 'tt_cv', 'tt_sd_adj','tt_reliability',\n",
    "                 'speed_ref_avg', 'speed_avg', 'speed_hist_avg','speed_sd','speed_hist_sd','speed_cv']\n",
    "\n",
    "\n",
    "# Normalization of features to range [0,1]\n",
    "linkdata = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(fresno_network.Z_data[features_list].values))\n",
    "linkdata.columns = features_list\n",
    "linkdata.insert(0, 'link_key', fresno_network.links_keys)\n",
    "\n",
    "fresno_network.load_features_data(linkdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = pd.read_csv(isl.dirs['input_folder'] + '/network-data/links/' \\\n",
    "                            + str(data_reader.options['selected_date']) + '-fresno-link-counts' + '.csv',\n",
    "                        converters={'link_key': ast.literal_eval})\n",
    "\n",
    "counts = dict(zip(counts_df['link_key'].values, counts_df['counts'].values))\n",
    "\n",
    "fresno_network.load_traffic_counts(counts=counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total link counts observations: 141\n",
      "Link coverage: 5.8%\n"
     ]
    }
   ],
   "source": [
    "total_counts_observations = np.count_nonzero(~np.isnan(np.array(list(counts.values()))))\n",
    "\n",
    "total_links = np.array(list(counts.values())).shape[0]\n",
    "\n",
    "print('\\nTotal link counts observations: ' + str(total_counts_observations))\n",
    "print('Link coverage: ' + \"{:.1%}\".format(round(total_counts_observations / total_links, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  network  nodes  links   ods  paths\n0  Fresno   1789   2413  6970  13905",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>network</th>\n      <th>nodes</th>\n      <th>links</th>\n      <th>ods</th>\n      <th>paths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fresno</td>\n      <td>1789</td>\n      <td>2413</td>\n      <td>6970</td>\n      <td>13905</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isl.descriptive_statistics.summary_table_networks([fresno_network])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Links performance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              alpha    beta           tf             k\ncount  2.413000e+03  2413.0  2413.000000  2.413000e+03\nmean   1.500000e-01     4.0     0.075482  1.439305e+09\nstd    2.776133e-17     0.0     0.085996  2.261116e+09\nmin    1.500000e-01     4.0     0.000000  1.800000e+03\n25%    1.500000e-01     4.0     0.000000  1.800000e+03\n50%    1.500000e-01     4.0     0.057738  1.800000e+03\n75%    1.500000e-01     4.0     0.106484  4.990000e+09\nmax    1.500000e-01     4.0     1.000000  4.990000e+09",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alpha</th>\n      <th>beta</th>\n      <th>tf</th>\n      <th>k</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.413000e+03</td>\n      <td>2413.0</td>\n      <td>2413.000000</td>\n      <td>2.413000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.075482</td>\n      <td>1.439305e+09</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.776133e-17</td>\n      <td>0.0</td>\n      <td>0.085996</td>\n      <td>2.261116e+09</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>1.800000e+03</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>1.800000e+03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.057738</td>\n      <td>1.800000e+03</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.106484</td>\n      <td>4.990000e+09</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>1.000000</td>\n      <td>4.990000e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_parameters_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     link_type  alpha  beta     tf             k  observed  counts  \\\n0        LWRLK   0.15   4.0  0.098  1.800000e+03         0     NaN   \n1        LWRLK   0.15   4.0  0.169  1.800000e+03         0     NaN   \n2        LWRLK   0.15   4.0  0.396  2.400000e+03         0     NaN   \n3        LWRLK   0.15   4.0  0.192  2.000000e+03         0     NaN   \n4        LWRLK   0.15   4.0  0.105  1.800000e+03         0     NaN   \n...        ...    ...   ...    ...           ...       ...     ...   \n2408     PQULK   0.15   4.0  0.000  4.990000e+09         0     NaN   \n2409     PQULK   0.15   4.0  0.000  4.990000e+09         0     NaN   \n2410     LWRLK   0.15   4.0  0.045  1.800000e+03         0     NaN   \n2411     LWRLK   0.15   4.0  0.107  2.400000e+03         0     NaN   \n2412     PQULK   0.15   4.0  0.000  4.990000e+09         0     NaN   \n\n      capacity [veh]  tt_ff [min]  speed_ff[mi/hr]  ...  bus_stops  \\\n0             1800.0        0.098               45  ...        0.0   \n1             1800.0        0.169               50  ...        0.0   \n2             2400.0        0.396               65  ...        0.0   \n3             2000.0        0.192               25  ...        0.0   \n4             1800.0        0.105               35  ...        0.0   \n...              ...          ...              ...  ...        ...   \n2408             inf        0.000            99999  ...        0.0   \n2409             inf        0.000            99999  ...        0.0   \n2410          1800.0        0.045               65  ...        0.0   \n2411          2400.0        0.107               65  ...        0.0   \n2412             inf        0.000            99999  ...        0.0   \n\n     intersections  tf_inrix  high_inc  low_inc  no_incidents  no_bus_stops  \\\n0         0.111111     0.221         1        0             1             1   \n1         0.000000     0.203         1        0             0             1   \n2         0.000000     0.396         1        0             0             1   \n3         0.111111     0.140         1        0             1             1   \n4         0.111111     0.105         1        0             1             1   \n...            ...       ...       ...      ...           ...           ...   \n2408      0.000000     0.000         0        0             0             0   \n2409      0.000000     0.000         0        0             0             0   \n2410      0.111111     0.040         1        0             1             1   \n2411      0.222222     0.099         0        1             0             1   \n2412      0.000000     0.000         0        0             0             0   \n\n      no_intersections  tt_sd_adj  tt_reliability  \n0                    0   0.109299        0.462004  \n1                    1   0.071056        0.609407  \n2                    1   0.000000        0.000000  \n3                    0   0.017797        0.701906  \n4                    0   0.000000        0.000000  \n...                ...        ...             ...  \n2408                 0   0.000000        0.000000  \n2409                 0   0.000000        0.000000  \n2410                 0   0.005085        0.825842  \n2411                 0   0.004827        0.798930  \n2412                 0   0.000000        0.000000  \n\n[2413 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link_type</th>\n      <th>alpha</th>\n      <th>beta</th>\n      <th>tf</th>\n      <th>k</th>\n      <th>observed</th>\n      <th>counts</th>\n      <th>capacity [veh]</th>\n      <th>tt_ff [min]</th>\n      <th>speed_ff[mi/hr]</th>\n      <th>...</th>\n      <th>bus_stops</th>\n      <th>intersections</th>\n      <th>tf_inrix</th>\n      <th>high_inc</th>\n      <th>low_inc</th>\n      <th>no_incidents</th>\n      <th>no_bus_stops</th>\n      <th>no_intersections</th>\n      <th>tt_sd_adj</th>\n      <th>tt_reliability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LWRLK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.098</td>\n      <td>1.800000e+03</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1800.0</td>\n      <td>0.098</td>\n      <td>45</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.111111</td>\n      <td>0.221</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.109299</td>\n      <td>0.462004</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LWRLK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.169</td>\n      <td>1.800000e+03</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1800.0</td>\n      <td>0.169</td>\n      <td>50</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.203</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.071056</td>\n      <td>0.609407</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LWRLK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.396</td>\n      <td>2.400000e+03</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2400.0</td>\n      <td>0.396</td>\n      <td>65</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.396</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LWRLK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.192</td>\n      <td>2.000000e+03</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2000.0</td>\n      <td>0.192</td>\n      <td>25</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.111111</td>\n      <td>0.140</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.017797</td>\n      <td>0.701906</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LWRLK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.105</td>\n      <td>1.800000e+03</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1800.0</td>\n      <td>0.105</td>\n      <td>35</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.111111</td>\n      <td>0.105</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2408</th>\n      <td>PQULK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.000</td>\n      <td>4.990000e+09</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>0.000</td>\n      <td>99999</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2409</th>\n      <td>PQULK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.000</td>\n      <td>4.990000e+09</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>0.000</td>\n      <td>99999</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2410</th>\n      <td>LWRLK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.045</td>\n      <td>1.800000e+03</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1800.0</td>\n      <td>0.045</td>\n      <td>65</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.111111</td>\n      <td>0.040</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.005085</td>\n      <td>0.825842</td>\n    </tr>\n    <tr>\n      <th>2411</th>\n      <td>LWRLK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.107</td>\n      <td>2.400000e+03</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2400.0</td>\n      <td>0.107</td>\n      <td>65</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.222222</td>\n      <td>0.099</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.004827</td>\n      <td>0.798930</td>\n    </tr>\n    <tr>\n      <th>2412</th>\n      <td>PQULK</td>\n      <td>0.15</td>\n      <td>4.0</td>\n      <td>0.000</td>\n      <td>4.990000e+09</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>0.000</td>\n      <td>99999</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2413 rows × 44 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table_links_df = fresno_network.Z_data\n",
    "estimation_reporter.write_table(df = summary_table_links_df, filename = 'links_data.csv', float_format = '%.3f')\n",
    "summary_table_links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              alpha    beta           tf             k     observed  \\\ncount  2.413000e+03  2413.0  2413.000000  2.413000e+03  2413.000000   \nmean   1.500000e-01     4.0     0.150823  1.439305e+09     0.058433   \nstd    2.776133e-17     0.0     0.172458  2.261116e+09     0.234610   \nmin    1.500000e-01     4.0     0.000000  1.800000e+03     0.000000   \n25%    1.500000e-01     4.0     0.000000  1.800000e+03     0.000000   \n50%    1.500000e-01     4.0     0.121000  1.800000e+03     0.000000   \n75%    1.500000e-01     4.0     0.205000  4.990000e+09     0.000000   \nmax    1.500000e-01     4.0     2.113000  4.990000e+09     1.000000   \n\n            counts  capacity [veh]  tt_ff [min]  speed_ff[mi/hr]  \\\ncount   141.000000          2413.0  2413.000000      2413.000000   \nmean   2213.607801             inf     0.150823     28872.664318   \nstd     849.965115             NaN     0.172458     45293.922006   \nmin     111.000000          1800.0     0.000000        15.000000   \n25%    1698.000000          1800.0     0.000000        40.000000   \n50%    2101.000000          1800.0     0.121000        45.000000   \n75%    2717.000000             NaN     0.205000     99999.000000   \nmax    4807.000000             inf     2.113000     99999.000000   \n\n           inrix_id  ...    bus_stops  intersections     tf_inrix  \\\ncount  1.468000e+03  ...  2413.000000    2413.000000  2413.000000   \nmean   9.131292e+08  ...     0.037505       0.097389     0.159494   \nstd    6.019207e+08  ...     0.110321       0.146641     0.181710   \nmin    1.685461e+08  ...     0.000000       0.000000     0.000000   \n25%    4.416712e+08  ...     0.000000       0.000000     0.000000   \n50%    4.498919e+08  ...     0.000000       0.000000     0.122000   \n75%    1.626675e+09  ...     0.000000       0.111111     0.225000   \nmax    1.626774e+09  ...     1.000000       1.000000     2.113000   \n\n          high_inc      low_inc  no_incidents  no_bus_stops  no_intersections  \\\ncount  2413.000000  2413.000000   2413.000000   2413.000000       2413.000000   \nmean      0.525073     0.186490      0.639867      0.587236          0.239536   \nstd       0.499474     0.389582      0.480138      0.492433          0.426889   \nmin       0.000000     0.000000      0.000000      0.000000          0.000000   \n25%       0.000000     0.000000      0.000000      0.000000          0.000000   \n50%       1.000000     0.000000      1.000000      1.000000          0.000000   \n75%       1.000000     0.000000      1.000000      1.000000          0.000000   \nmax       1.000000     1.000000      1.000000      1.000000          1.000000   \n\n         tt_sd_adj  tt_reliability  \ncount  2413.000000     2413.000000  \nmean      0.046804        0.399915  \nstd       0.071903        0.351537  \nmin       0.000000        0.000000  \n25%       0.000000        0.000000  \n50%       0.017366        0.549181  \n75%       0.071056        0.723356  \nmax       1.000000        1.000000  \n\n[8 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alpha</th>\n      <th>beta</th>\n      <th>tf</th>\n      <th>k</th>\n      <th>observed</th>\n      <th>counts</th>\n      <th>capacity [veh]</th>\n      <th>tt_ff [min]</th>\n      <th>speed_ff[mi/hr]</th>\n      <th>inrix_id</th>\n      <th>...</th>\n      <th>bus_stops</th>\n      <th>intersections</th>\n      <th>tf_inrix</th>\n      <th>high_inc</th>\n      <th>low_inc</th>\n      <th>no_incidents</th>\n      <th>no_bus_stops</th>\n      <th>no_intersections</th>\n      <th>tt_sd_adj</th>\n      <th>tt_reliability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.413000e+03</td>\n      <td>2413.0</td>\n      <td>2413.000000</td>\n      <td>2.413000e+03</td>\n      <td>2413.000000</td>\n      <td>141.000000</td>\n      <td>2413.0</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>1.468000e+03</td>\n      <td>...</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n      <td>2413.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.150823</td>\n      <td>1.439305e+09</td>\n      <td>0.058433</td>\n      <td>2213.607801</td>\n      <td>inf</td>\n      <td>0.150823</td>\n      <td>28872.664318</td>\n      <td>9.131292e+08</td>\n      <td>...</td>\n      <td>0.037505</td>\n      <td>0.097389</td>\n      <td>0.159494</td>\n      <td>0.525073</td>\n      <td>0.186490</td>\n      <td>0.639867</td>\n      <td>0.587236</td>\n      <td>0.239536</td>\n      <td>0.046804</td>\n      <td>0.399915</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.776133e-17</td>\n      <td>0.0</td>\n      <td>0.172458</td>\n      <td>2.261116e+09</td>\n      <td>0.234610</td>\n      <td>849.965115</td>\n      <td>NaN</td>\n      <td>0.172458</td>\n      <td>45293.922006</td>\n      <td>6.019207e+08</td>\n      <td>...</td>\n      <td>0.110321</td>\n      <td>0.146641</td>\n      <td>0.181710</td>\n      <td>0.499474</td>\n      <td>0.389582</td>\n      <td>0.480138</td>\n      <td>0.492433</td>\n      <td>0.426889</td>\n      <td>0.071903</td>\n      <td>0.351537</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>1.800000e+03</td>\n      <td>0.000000</td>\n      <td>111.000000</td>\n      <td>1800.0</td>\n      <td>0.000000</td>\n      <td>15.000000</td>\n      <td>1.685461e+08</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>1.800000e+03</td>\n      <td>0.000000</td>\n      <td>1698.000000</td>\n      <td>1800.0</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n      <td>4.416712e+08</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.121000</td>\n      <td>1.800000e+03</td>\n      <td>0.000000</td>\n      <td>2101.000000</td>\n      <td>1800.0</td>\n      <td>0.121000</td>\n      <td>45.000000</td>\n      <td>4.498919e+08</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.122000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.017366</td>\n      <td>0.549181</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>0.205000</td>\n      <td>4.990000e+09</td>\n      <td>0.000000</td>\n      <td>2717.000000</td>\n      <td>NaN</td>\n      <td>0.205000</td>\n      <td>99999.000000</td>\n      <td>1.626675e+09</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.225000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.071056</td>\n      <td>0.723356</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.500000e-01</td>\n      <td>4.0</td>\n      <td>2.113000</td>\n      <td>4.990000e+09</td>\n      <td>1.000000</td>\n      <td>4807.000000</td>\n      <td>inf</td>\n      <td>2.113000</td>\n      <td>99999.000000</td>\n      <td>1.626774e+09</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.113000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table_links_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Travel demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cumulative trips OD matrix\n",
    "# isl.visualization.Artist().cumulative_demand(Q= fresno_network.Q,\n",
    "#                          folderpath = estimation_reporter.dirs['estimation_folder'],\n",
    "#                          filename = 'cumulative_OD_matrix.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilevel Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_function = isl.estimation.UtilityFunction(\n",
    "    features_Y=['tt'],\n",
    "    initial_values={'tt': 0},\n",
    ")\n",
    "\n",
    "equilibrator_norefined = isl.equilibrium.LUE_Equilibrator(\n",
    "    network=fresno_network,\n",
    "    paths_generator=paths_generator,\n",
    "    utility_function=utility_function,\n",
    "    max_iters=100,\n",
    "    method='fw',\n",
    "    iters_fw=10,\n",
    "    column_generation={'n_paths': 18, 'ods_coverage': 0.25, 'paths_selection': 10, 'ods_sampling': 'demand_sequentially'},\n",
    "    path_size_correction=1\n",
    ")\n",
    "\n",
    "outer_optimizer_norefined = isl.estimation.OuterOptimizer(\n",
    "    method='ngd',\n",
    "    iters=1,\n",
    "    eta=2e-1,\n",
    ")\n",
    "\n",
    "learner_norefined = isl.estimation.Learner(\n",
    "    equilibrator=equilibrator_norefined,\n",
    "    outer_optimizer=outer_optimizer_norefined,\n",
    "    utility_function=utility_function,\n",
    "    network=fresno_network,\n",
    "    name = 'norefined'\n",
    ")\n",
    "\n",
    "equilibrator_refined = isl.equilibrium.LUE_Equilibrator(\n",
    "    network=fresno_network,\n",
    "    paths_generator=paths_generator,\n",
    "    utility_function=utility_function,\n",
    "    max_iters=100,\n",
    "    method='fw',\n",
    "    iters_fw=10,\n",
    "    # column_generation={'n_paths': 12, 'ods_coverage': 0.1, 'paths_selection': None},\n",
    "    path_size_correction=1\n",
    ")\n",
    "\n",
    "outer_optimizer_refined = isl.estimation.OuterOptimizer(\n",
    "    method='lm',\n",
    "    # method='ngd',\n",
    "    iters=1,\n",
    "    # eta=1e-1,\n",
    ")\n",
    "\n",
    "learner_refined = isl.estimation.Learner(\n",
    "    network=fresno_network,\n",
    "    equilibrator=equilibrator_refined,\n",
    "    outer_optimizer=outer_optimizer_refined,\n",
    "    utility_function=utility_function,\n",
    "    name = 'refined'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Benchmark predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive prediction using mean counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objective function under mean count prediction: 101,141,667.7\n"
     ]
    }
   ],
   "source": [
    "mean_counts_prediction_loss, mean_count_benchmark_model \\\n",
    "    = isl.estimation.mean_count_prediction(counts=np.array(list(counts.values()))[:, np.newaxis])\n",
    "\n",
    "print('\\nObjective function under mean count prediction: ' + '{:,}'.format(round(mean_counts_prediction_loss, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive prediction where travelers make equilikely choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function under equilikely route choices: 279,378,072.3\n"
     ]
    }
   ],
   "source": [
    "equilikely_prediction_loss, predicted_counts_equilikely \\\n",
    "    = isl.estimation.loss_counts_equilikely_choices(\n",
    "    network = fresno_network,\n",
    "    equilibrator=equilibrator_norefined,\n",
    "    counts=fresno_network.observed_counts_vector,\n",
    "    utility_function=utility_function)\n",
    "\n",
    "print('Objective function under equilikely route choices: ' + '{:,}'.format(round(equilikely_prediction_loss, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Model with travel time feature only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No refined stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bilevel optimization for Fresno network \n",
      "\n",
      "Initial theta: {'tt': '0.0E+00'}\n"
     ]
    }
   ],
   "source": [
    "learning_results_norefined_traveltime_model, inference_results_norefined_traveltime_model, best_iter_norefined_traveltime_model = \\\n",
    "    learner_norefined.statistical_inference(h0=0, bilevel_iters=10, alpha=0.05, link_report=False, iteration_report = False)\n",
    "\n",
    "theta_norefined_traveltime_model = learning_results_norefined_traveltime_model[best_iter_norefined_traveltime_model]['theta']\n",
    "\n",
    "paths_generator.write_paths(network=fresno_network, overwrite_input=False, filename = 'paths-traveltime-model-Fresno.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refined stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "learner_refined.utility_function.initial_values = theta_norefined_traveltime_model\n",
    "\n",
    "learning_results_refined_traveltime_model, inference_results_refined_traveltime_model, best_iter_refined_traveltime_model = \\\n",
    "    learner_refined.statistical_inference(h0=0, bilevel_iters=10, alpha=0.05, link_report=False, iteration_report = False)\n",
    "\n",
    "theta_refined_traveltime_model = learning_results_refined_traveltime_model[best_iter_refined_traveltime_model]['theta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "estimation_reporter.add_items_report(\n",
    "    selected_date = data_reader.options['selected_date'],\n",
    "    selected_hour = data_reader.options['selected_hour'],\n",
    "    selected_od_periods = data_reader.options['od_periods'],\n",
    "    mean_counts=round(mean_count_benchmark_model,1),\n",
    "    mean_counts_prediction_loss = round(mean_counts_prediction_loss,1),\n",
    "    equilikely_prediction_loss = round(equilikely_prediction_loss,1)\n",
    ")\n",
    "\n",
    "estimation_reporter.add_items_report(\n",
    "    theta_norefined=theta_norefined_traveltime_model,\n",
    "    theta_refined= theta_refined_traveltime_model,\n",
    "    best_objective_norefined = round(learning_results_norefined_traveltime_model[best_iter_norefined_traveltime_model]['objective'],1),\n",
    "    best_objective_refined = round(learning_results_refined_traveltime_model[best_iter_refined_traveltime_model]['objective'],1),\n",
    ")\n",
    "\n",
    "# Summary with most relevant options, prediction error, initial parameters, etc\n",
    "estimation_reporter.write_estimation_report(\n",
    "    network=fresno_network,\n",
    "    learners=[learner_norefined, learner_refined],\n",
    "    utility_function=utility_function)\n",
    "\n",
    "# Write tables with results on learning and inference\n",
    "estimation_reporter.write_learning_tables(\n",
    "    results_norefined=learning_results_norefined_traveltime_model,\n",
    "    results_refined=learning_results_refined_traveltime_model,\n",
    "    network = fresno_network,\n",
    "    utility_function = utility_function)\n",
    "\n",
    "estimation_reporter.write_inference_tables(\n",
    "    results_norefined=inference_results_norefined_traveltime_model,\n",
    "    results_refined=inference_results_refined_traveltime_model,\n",
    "    float_format = '%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results_traveltime_model_df = isl.descriptive_statistics \\\n",
    "    .get_loss_and_estimates_over_iterations(results_norefined=learning_results_norefined_traveltime_model\n",
    "                                            , results_refined=learning_results_refined_traveltime_model)\n",
    "\n",
    "fig = isl.visualization.Artist().convergence(\n",
    "    results_norefined_df=results_traveltime_model_df[results_traveltime_model_df['stage'] == 'norefined'],\n",
    "    results_refined_df=results_traveltime_model_df[results_traveltime_model_df['stage'] == 'refined'],\n",
    "    filename='convergence_' + fresno_network.key,\n",
    "    methods=[outer_optimizer_norefined.method.key, outer_optimizer_refined.method.key],\n",
    "    folder = estimation_reporter.dirs['estimation_folder'],\n",
    "    simulated_data = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of errors across link counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "best_predicted_counts_norefined = np.array(list(learning_results_norefined_traveltime_model[best_iter_norefined_traveltime_model]['x'].values()))[:, np.newaxis]\n",
    "best_predicted_counts_refined = np.array(list(learning_results_refined_traveltime_model[best_iter_refined_traveltime_model]['x'].values()))[:, np.newaxis]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey='all', tight_layout=True, figsize=(8, 4))\n",
    "\n",
    "axs[0].hist(isl.estimation.error_by_link(observed_counts=np.array(list(counts.values()))[:, np.newaxis],\n",
    "                                         predicted_counts=best_predicted_counts_norefined))\n",
    "axs[1].hist(isl.estimation.error_by_link(observed_counts=np.array(list(counts.values()))[:, np.newaxis],\n",
    "                                         predicted_counts=best_predicted_counts_refined))\n",
    "\n",
    "for axi in [axs[0], axs[1]]:\n",
    "    axi.tick_params(axis='x', labelsize=16)\n",
    "    axi.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(estimation_reporter.dirs['estimation_folder'] + '/' + 'distribution_predicted_error_counts.pdf',\n",
    "            pad_inches=0.1, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### c) Model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "utility_function_full_model = isl.estimation.UtilityFunction(\n",
    "    features_Y=['tt'],\n",
    "#    features_Z= ['incidents'],\n",
    "    features_Z= ['incidents', 'tt_cv','median_inc', 'bus_stops', 'intersections'],\n",
    "    # initial_values = {'median_inc': 1.5, 'bus_stops':0},\n",
    "    signs = {'tt': '-', 'tt_cv':'-', 'incidents':'-', 'intersections':'-', 'bus_stops':'-', 'median_inc':'+'},\n",
    "    fixed = {'tt': True}\n",
    ")\n",
    "\n",
    "# Update utility functions of no refined and refined learners\n",
    "learner_norefined.utility_function = utility_function_full_model\n",
    "learner_refined.utility_function = utility_function_full_model\n",
    "\n",
    "#Initialize value with the estimate obtained from b)\n",
    "learner_norefined.utility_function.initial_values = theta_refined_traveltime_model\n",
    "# learner_norefined.utility_function.zero_initializer()\n",
    "\n",
    "learner_norefined.outer_optimizer.method.eta = 5e-1\n",
    "learner_refined.outer_optimizer.method.eta = 5e-1\n",
    "\n",
    "paths_generator.read_paths(network=fresno_network, update_incidence_matrices=True,\n",
    "                           filename = 'paths-traveltime-model-Fresno.csv',\n",
    "                           folderpath = isl.config.dirs['write_network_data'] + 'paths/'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### No refined stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "learning_results_norefined_full_model, inference_results_norefined_full_model, best_iter_norefined_full_model = \\\n",
    "    learner_norefined.statistical_inference(h0=0, bilevel_iters=10, alpha=0.05, link_report=False, iteration_report = True,\n",
    "                                            parameters_constraints = {'fixed': True, 'sign': True})\n",
    "\n",
    "theta_norefined_full_model = learning_results_norefined_full_model[best_iter_norefined_full_model]['theta']\n",
    "\n",
    "paths_generator.write_paths(network=fresno_network, overwrite_input=False, filename = 'paths-full-model-Fresno.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Refined stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features_Y,features_Z = isl.estimation.feature_selection(utility_function_full_model,\n",
    "                                                          theta = theta_norefined_full_model,\n",
    "                                                          criterion = 'sign')\n",
    "\n",
    "utility_function_full_model = isl.estimation.UtilityFunction(\n",
    "    features_Y = features_Y,\n",
    "    features_Z = features_Z,\n",
    "    fixed = {'tt': True}\n",
    ")\n",
    "\n",
    "learner_norefined.utility_function = utility_function_full_model\n",
    "learner_refined.utility_function = utility_function_full_model\n",
    "\n",
    "learner_refined.utility_function.initial_values = theta_norefined_full_model\n",
    "\n",
    "learning_results_refined_full_model, inference_results_refined_full_model, best_iter_refined_full_model = \\\n",
    "    learner_refined.statistical_inference(h0=0, bilevel_iters=10, alpha=0.05, link_report=False, iteration_report = True,\n",
    "                                            parameters_constraints = {'fixed': False, 'sign': False})\n",
    "\n",
    "theta_refined_full_model = learning_results_refined_full_model[best_iter_refined_full_model]['theta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "estimation_reporter.add_items_report(\n",
    "    selected_date = data_reader.options['selected_date'],\n",
    "    selected_hour = data_reader.options['selected_hour'],\n",
    "    selected_od_periods = data_reader.options['od_periods'],\n",
    "    mean_counts=round(mean_count_benchmark_model,1),\n",
    "    mean_counts_prediction_loss = round(mean_counts_prediction_loss,1),\n",
    "    equilikely_prediction_loss = round(equilikely_prediction_loss,1)\n",
    ")\n",
    "\n",
    "estimation_reporter.add_items_report(\n",
    "    theta_norefined=theta_norefined_full_model,\n",
    "    theta_refined= theta_refined_full_model,\n",
    "    best_objective_norefined = round(learning_results_norefined_full_model[best_iter_norefined_full_model]['objective'],1),\n",
    "    best_objective_refined = round(learning_results_refined_full_model[best_iter_refined_full_model]['objective'],1),\n",
    ")\n",
    "\n",
    "estimation_reporter.write_estimation_report(\n",
    "    network=fresno_network,\n",
    "    learners=[learner_norefined, learner_refined],\n",
    "    utility_function=utility_function_full_model)\n",
    "\n",
    "estimation_reporter.write_learning_tables(\n",
    "    results_norefined=learning_results_norefined_full_model,\n",
    "    results_refined=learning_results_refined_full_model,\n",
    "    network = fresno_network,\n",
    "    utility_function = utility_function_full_model)\n",
    "\n",
    "estimation_reporter.write_inference_tables(\n",
    "    results_norefined=inference_results_norefined_full_model,\n",
    "    results_refined=inference_results_refined_full_model,\n",
    "    float_format = '%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results_full_model_df = isl.descriptive_statistics \\\n",
    "    .get_loss_and_estimates_over_iterations(results_norefined=learning_results_norefined_full_model,\n",
    "                                            results_refined=learning_results_refined_full_model)\n",
    "\n",
    "\n",
    "# Convergence with curves for each parameter and comparing the travel time and full models\n",
    "fig = isl.visualization.Artist().convergence_models(\n",
    "    results_dfs={'traveltime_model': results_traveltime_model_df, 'full_model': results_full_model_df},\n",
    "    features= {'tt': 'travel time', 'tt_cv':'coeficient of variation of travel time', 'incidents':'incidents', 'intersections':'intersections', 'bus_stops':'bus_stops', 'median_inc':'median income area'},\n",
    "    filename='convergence_traveltime_and_full_models_' + fresno_network.key,\n",
    "    folder=estimation_reporter.dirs['estimation_folder']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Model with feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "utility_function_feature_engineering_model = isl.estimation.UtilityFunction(\n",
    "    features_Y=['tt'],\n",
    "    features_Z= ['tt_sd_asj', 'no_incidents', 'no_bus_stops', 'no_intersections', 'low_inc'],\n",
    "    signs = {'tt': '-', 'tt_sd_adj':'-', 'no_incidents':'+', 'no_bus_stops':'+', 'no_intersections':'+', 'low_inc':'-'},\n",
    "    fixed = {'tt': True}\n",
    ")\n",
    "\n",
    "# Update utility functions of no refined and refined learners\n",
    "learner_norefined.utility_function = utility_function_feature_engineering_model\n",
    "learner_refined.utility_function = utility_function_feature_engineering_model\n",
    "\n",
    "#Initialize travel time estimate with the one obtained from b) and load those paths as well\n",
    "learner_norefined.utility_function.initial_values = theta_refined_traveltime_model\n",
    "\n",
    "paths_generator.read_paths(network=fresno_network, update_incidence_matrices=True,\n",
    "                           filename = 'paths-traveltime-model-Fresno.csv',\n",
    "                           folderpath = isl.config.dirs['write_network_data'] + 'paths/'\n",
    "                           )\n",
    "\n",
    "learner_norefined.outer_optimizer.method.eta = 5e-1\n",
    "learner_refined.outer_optimizer.method.eta = 5e-1\n",
    "\n",
    "estimation_reporter = isl.writer.Reporter(folderpath = isl.config.dirs['output_folder'] + 'estimations/' + network_name, seed =_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No refined stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "learning_results_norefined_feature_engineering_model, inference_results_norefined_feature_engineering_model, best_iter_norefined_feature_engineering_model = \\\n",
    "    learner_norefined.statistical_inference(h0=0, bilevel_iters=10, alpha=0.05, link_report=False, iteration_report = True,\n",
    "                            parameters_constraints = {'fixed': True, 'sign': True})\n",
    "\n",
    "theta_norefined_feature_engineering_model = learning_results_norefined_feature_engineering_model[best_iter_norefined_feature_engineering_model]['theta']\n",
    "\n",
    "paths_generator.write_paths(network=fresno_network, overwrite_input=False, filename = 'paths-feature-engineering-model-Fresno.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refined stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "features_Y,features_Z = isl.estimation.feature_selection(utility_function_feature_engineering_model,\n",
    "                                                          theta = theta_norefined_feature_engineering_model,\n",
    "                                                          criterion = 'sign')\n",
    "\n",
    "utility_function_feature_engineering_model = isl.estimation.UtilityFunction(\n",
    "    features_Y = features_Y,\n",
    "    features_Z = features_Z\n",
    ")\n",
    "\n",
    "learner_norefined.utility_function = utility_function_feature_engineering_model\n",
    "learner_refined.utility_function = utility_function_feature_engineering_model\n",
    "\n",
    "learner_refined.utility_function.initial_values = theta_norefined_feature_engineering_model\n",
    "\n",
    "learning_results_refined_feature_engineering_model, inference_results_refined_feature_engineering_model, best_iter_refined_feature_engineering_model = \\\n",
    "    learner_refined.statistical_inference(h0=0, bilevel_iters=10, alpha=0.05, link_report=False, iteration_report = True,\n",
    "                                          parameters_constraints = {'fixed': False, 'sign': False})\n",
    "\n",
    "theta_refined_feature_engineering_model = learning_results_refined_feature_engineering_model[best_iter_refined_feature_engineering_model]['theta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "estimation_reporter.add_items_report(\n",
    "    selected_date = data_reader.options['selected_date'],\n",
    "    selected_hour = data_reader.options['selected_hour'],\n",
    "    selected_od_periods = data_reader.options['od_periods'],\n",
    "    mean_counts=round(mean_count_benchmark_model,1),\n",
    "    mean_counts_prediction_loss = round(mean_counts_prediction_loss,1),\n",
    "    equilikely_prediction_loss = round(equilikely_prediction_loss,1)\n",
    ")\n",
    "\n",
    "estimation_reporter.add_items_report(\n",
    "    theta_norefined=theta_norefined_feature_engineering_model,\n",
    "    theta_refined= theta_refined_feature_engineering_model,\n",
    "    best_objective_norefined = round(learning_results_norefined_feature_engineering_model[best_iter_norefined_feature_engineering_model]['objective'],1),\n",
    "    best_objective_refined = round(learning_results_refined_feature_engineering_model[best_iter_refined_feature_engineering_model]['objective'],1),\n",
    ")\n",
    "\n",
    "estimation_reporter.write_estimation_report(\n",
    "    network=fresno_network,\n",
    "    learners=[learner_norefined, learner_refined],\n",
    "    utility_function=utility_function_feature_engineering_model)\n",
    "\n",
    "estimation_reporter.write_learning_tables(\n",
    "    results_norefined=learning_results_norefined_feature_engineering_model,\n",
    "    results_refined=learning_results_refined_feature_engineering_model,\n",
    "    network = fresno_network,\n",
    "    utility_function = utility_function_feature_engineering_model)\n",
    "\n",
    "estimation_reporter.write_inference_tables(\n",
    "    results_norefined=inference_results_norefined_feature_engineering_model,\n",
    "    results_refined=inference_results_refined_feature_engineering_model,\n",
    "    float_format = '%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results_feature_engineering_model_df = isl.descriptive_statistics \\\n",
    "    .get_loss_and_estimates_over_iterations(results_norefined=learning_results_norefined_feature_engineering_model,\n",
    "                                            results_refined=learning_results_refined_feature_engineering_model)\n",
    "\n",
    "\n",
    "# Convergence with curves for each parameter and comparing the travel time and full models\n",
    "fig = isl.visualization.Artist().convergence_models(\n",
    "    results_dfs={'traveltime_model': results_traveltime_model_df, 'full_model': results_feature_engineering_model_df},\n",
    "    features= {'tt': 'travel time', 'tt_sd_adj':'adjusted std of travel time', 'no_incidents':'no incidents', 'no_intersections':'no intersections', 'no_bus_stops':'no bus_stops', 'low_inc':'low income area'},\n",
    "    filename='convergence_traveltime_and_full_models_' + fresno_network.key,\n",
    "    folder=estimation_reporter.dirs['estimation_folder']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-isuelogit",
   "language": "python",
   "name": "venv-isuelogit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}